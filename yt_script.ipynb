{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5ZntJR3n6FBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q youtube-transcript-api langchain-community langchain-openai \\ faiss-cpu tiktoken python-dotenv\n"
      ],
      "metadata": {
        "id": "qHboL976vsrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "902dffd1-fa0f-4335-9c57-9782c1c89f65"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi,TranscriptsDisabled\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.prompts import PromptTemplate\n"
      ],
      "metadata": {
        "id": "MRF72Talw0Sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q youtube-transcript-api langchain-community langchain-openai faiss-cpu tiktoken python-dotenv"
      ],
      "metadata": {
        "id": "tFUFy-2N6wMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "import os, requests\n",
        "from langchain.llms import BaseLLM\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from pydantic import Field, BaseModel\n",
        "\n",
        "# Set the environment variable before loading\n",
        "# Using a standard name for consistency and clarity\n",
        "os.environ[\"TOGETHER_AI_API_KEY\"]=\"tgp_v1_OSpvv_Dzn_65Tk0F6nEMJAcf8eyqMLgiVBAhqy8djvM\"\n",
        "\n",
        "# Load .env (if you were using a .env file, this would load it)\n",
        "# Since we're setting it directly, load_dotenv might not be strictly necessary here,\n",
        "# but keep it if you plan to use a .env file later.\n",
        "load_dotenv()\n",
        "\n",
        "# Load the API key from the environment variable\n",
        "API_KEY = os.getenv(\"TOGETHER_AI_API_KEY\")\n",
        "\n",
        "# Add a check to ensure the API key was loaded\n",
        "if not API_KEY:\n",
        "    raise ValueError(\"TOGETHER_AI_API_KEY environment variable not set.\")\n",
        "\n",
        "\n",
        "from langchain_core.outputs import LLMResult, Generation\n",
        "from typing import List, Optional, Any\n",
        "\n",
        "class TogetherAIWrapper(BaseLLM):\n",
        "    api_key: str = Field(..., description=\"API key for Together.ai\")\n",
        "\n",
        "    def __init__(self, api_key: str,**kwargs: Any):\n",
        "      super().__init__(api_key=api_key,**kwargs)\n",
        "\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"together_ai\"\n",
        "\n",
        "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
        "        url = \"https://api.together.xyz/inference\"\n",
        "        data = {\n",
        "            \"model\": \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
        "            \"prompt\": prompt,\n",
        "            \"max_tokens\": 300,\n",
        "            \"temperature\": 0.7,\n",
        "            \"top_p\": 0.9\n",
        "        }\n",
        "        headers = {\n",
        "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "\n",
        "        response = requests.post(url, headers=headers, json=data)\n",
        "        if response.status_code == 200:\n",
        "            # Assuming the API returns the text directly in the \"output\" key\n",
        "            # If the structure is ['output']['choices'][0]['text'], adjust here\n",
        "            response_data = response.json()\n",
        "            # Let's try to get the text in a way that's compatible with the original working version\n",
        "            # and the structure needed for Generation.\n",
        "            # The original working version used ['output']['choices'][0]['text']\n",
        "            try:\n",
        "                return response_data['output']['choices'][0]['text']\n",
        "            except (KeyError, IndexError) as e:\n",
        "                raise Exception(f\"Error parsing Together.ai API response: {e}. Response: {response_data}\")\n",
        "\n",
        "        else:\n",
        "            raise Exception(f\"Error: {response.status_code}, {response.text}\")\n",
        "\n",
        "    def _generate(\n",
        "        self,\n",
        "        prompts: List[str],\n",
        "        stop: Optional[List[str]] = None,\n",
        "        **kwargs: Any,\n",
        "    ) -> LLMResult:\n",
        "        generations = []\n",
        "        for prompt in prompts:\n",
        "            text = self._call(prompt, stop=stop)\n",
        "            # Create a Generation object with the retrieved text\n",
        "            generations.append([Generation(text=text)])\n",
        "        # LLMResult expects a list of lists of Generation objects\n",
        "        return LLMResult(generations=generations)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg1TAN3q-NlY",
        "outputId": "703ae4cf-61c5-49fb-f736-10071bd88095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ML can improve healthcare by predicting and diagnosing diseases, developing personalized treatment plans, analyzing medical images, improving patient outcomes and reducing healthcare costs.\n",
            "\n",
            "Explanation: \n",
            "\n",
            "1. Predicting and diagnosing diseases: ML algorithms can analyze vast amounts of patient data to identify patterns and risk factors for various diseases. This can help healthcare providers to diagnose diseases early and develop effective treatment plans.\n",
            "2. Developing personalized treatment plans: ML algorithms can analyze patient data to identify the most effective treatment options for individual patients. This can help healthcare providers to develop personalized treatment plans that are tailored to each patient's unique needs and circumstances.\n",
            "3. Analyzing medical images: ML algorithms can analyze medical images such as X-rays, CT scans, and MRIs to identify abnormalities and assist healthcare providers in diagnosing diseases.\n",
            "4. Improving patient outcomes: ML can be used to analyze patient data to identify factors that are associated with better patient outcomes. This can help healthcare providers to develop interventions that are designed to improve patient outcomes.\n",
            "5. Reducing healthcare costs: ML can be used to identify inefficiencies in healthcare systems and develop interventions that are designed to reduce healthcare costs. This can help to improve the overall quality and affordability of healthcare.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 1A --Indexing (Document INgestion)\n",
        "\n",
        "video_id = \"Gfr50f6ZBvo\"\n",
        "try:\n",
        "  transcript_list = YouTubeTranscriptApi.get_transcript(video_id,languages=[\"en\"])\n",
        "  transcript = \" \".join(chunk[\"text\"]for chunk in transcript_list)\n",
        "  print(transcript)\n",
        "except TranscriptsDisabled:\n",
        "  print(\"No caption available\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "JrRp5d9jAY3v",
        "outputId": "f32379e6-6477-4881-92db-390443f7c66a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'TranscriptsDisabled' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d4c5b9c6debc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mtranscript_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYouTubeTranscriptApi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transcript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlanguages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mtranscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtranscript_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'YouTubeTranscriptApi' is not defined",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d4c5b9c6debc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mtranscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtranscript_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mexcept\u001b[0m \u001b[0mTranscriptsDisabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No caption available\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TranscriptsDisabled' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 1b -- (text splitting)\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
        "chunks = splitter.create_documents([transcript])\n"
      ],
      "metadata": {
        "id": "5N_1BNQoE_V9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbZCAWjzFiwO",
        "outputId": "0c949e97-dea4-40d7-cc22-c3a40409994f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "168"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1c&d ---Creating embedding and storing in vectorStorees\n"
      ],
      "metadata": {
        "id": "zqkz_LMUGDDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en\")\n",
        "vector_store = FAISS.from_documents(chunks,embeddings)\n",
        "\n"
      ],
      "metadata": {
        "id": "6bEq5fskGNn-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "outputId": "14e5b2fd-3800-4d4d-a44c-81a6fe5ddc3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "Module langchain_community.embeddings not found. Please install langchain-community to access this module. You can install it using `pip install -U langchain-community`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/_api/module_import.py\u001b[0m in \u001b[0;36mimport_by_name\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_community'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-dfec5a3334f9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHuggingFaceEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHuggingFaceEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"BAAI/bge-small-en\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvector_store\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/embeddings/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;34m\"\"\"Look up attributes dynamically.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_import_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/_api/module_import.py\u001b[0m in \u001b[0;36mimport_by_name\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"langchain_community\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                     raise ModuleNotFoundError(\n\u001b[0m\u001b[1;32m     73\u001b[0m                         \u001b[0;34mf\"Module {new_module} not found. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                         \u001b[0;34m\"Please install langchain-community to access this module. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: Module langchain_community.embeddings not found. Please install langchain-community to access this module. You can install it using `pip install -U langchain-community`",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2 -- Retrieval\n"
      ],
      "metadata": {
        "id": "A1IrzehwIS4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vector_store.as_retriever(search_type=\"similarity\",search_kwargs={\"k\":4})"
      ],
      "metadata": {
        "id": "fUaaz-flIpvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = TogetherAIWrapper(\"tgp_v1_OSpvv_Dzn_65Tk0F6nEMJAcf8eyqMLgiVBAhqy8djvM\")\n"
      ],
      "metadata": {
        "id": "SqMrobk7LYz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "promt = PromptTemplate(template=\"\"\"\n",
        "you are a helpful assistant.\n",
        "Answer Only from provided transcript context\n",
        "If the context is insufficient. just say you don't know ,\n",
        "{context}\n",
        "Question:{question}\"\"\",input_variables=[\"context\",\"question\"])"
      ],
      "metadata": {
        "id": "Ysh90TbpLqC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question= \"is the topic of alien discussed in this video? if yes then what was discussed\"\n",
        "retrived_doc = retriever.invoke(question)"
      ],
      "metadata": {
        "id": "E5igogHvNVg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content_text = \"\\n\\n\".join(doc.page_content for doc in retrived_doc)"
      ],
      "metadata": {
        "id": "wnuoHfO1N-Vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_prompt = promt.invoke({\"context\":content_text,\"question\":question})"
      ],
      "metadata": {
        "id": "QGrt04iMOoxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ShqUjULvOzXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer = llm.invoke(final_prompt)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCrAAlNLP5HU",
        "outputId": "b6a6796e-790c-441b-88a2-e8bcabb35ff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?\n",
            "\n",
            "Answer: The topic of aliens is discussed in this video, but it is not the main topic. The main topic is the relationship between artificial intelligence and creativity. The discussion about aliens is brought up in the context of how AI systems might be able to create something original, and the idea that AI systems might be able to surpass human creativity in certain areas. The discussion about aliens is used as an example of how AI systems might be able to create something original, and the idea that AI systems might be able to surpass human creativity in certain areas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a Chain ...."
      ],
      "metadata": {
        "id": "e4xnuJZLSI8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableParallel,RunnablePassthrough,RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "lNOmqRR8SMwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_doc(retrived_doc):\n",
        "  content_text=\"\\n\\n\".join(doc.page_content for doc in retrived_doc)\n",
        "  return content_text"
      ],
      "metadata": {
        "id": "maR_u9o_SnKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parallel_chain = RunnableParallel({\n",
        "    \"context\":retriever | RunnableLambda(format_doc),\n",
        "    \"question\":RunnablePassthrough()\n",
        "})\n"
      ],
      "metadata": {
        "id": "vJOWZwOdS-hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = StrOutputParser()\n"
      ],
      "metadata": {
        "id": "YwCnG3ICVYkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_chain = parallel_chain|promt|llm|parser"
      ],
      "metadata": {
        "id": "xQDbM9BHVgHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_chain.invoke(\"can you summarize this video\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "c06cANq9VrY-",
        "outputId": "036dd959-fb48-4a3f-895f-9ed084af55f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' in a few sentences?\\n\\nAnswer:\\nThe video discusses the evolution of artificial intelligence, specifically in the field of game playing. The development of AlphaGo and AlphaZero, and their ability to play against themselves and generalize to any two player game, is highlighted. The video also discusses the importance of clear and simple explanations as a sign of understanding and intelligence.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    }
  ]
}